<div align=center>
<img src="https://github.com/XinJingHao/RL-Algorithms-by-Pytorch/blob/main/RL_PYTORCH.jpg" width=500 />
</div>

<div align=center>
Clean, Robust, and Unified implementation of classical Deep Reinforcement Learning Algorithms 
</div>

<br/>
<br/>

## Link of my code:
+ [Q-learning:](https://github.com/XinJingHao/Q-learning)
+ [DQN/DDQN on Classic Control:](https://github.com/XinJingHao/DQN-DDQN-Pytorch)
+ [DQN/DDQN on Atari Game:](https://github.com/XinJingHao/DQN-DDQN-Atari-Pytorch)
+ [Prioritized DQN/DDQN on Classic Control:](https://github.com/XinJingHao/Prioritized-DQN-DDQN-Pytorch)
+ [Proximal Policy Optimization(PPO) for Discrete Action Space:](https://github.com/XinJingHao/PPO-Discrete-Pytorch)
+ [Proximal Policy Optimization(PPO) for Continuous Action Space:](https://github.com/XinJingHao/PPO-Continuous-Pytorch)
+ [Deep Deternimistic Policy Gradient(DDPG):](https://github.com/XinJingHao/DDPG-Pytorch)
+ [Twin Delayed Deep Deterministic Policy Gradient(TD3):](https://github.com/XinJingHao/TD3-Pytorch)
+ [Soft Actor Critic(SAC) for Discrete Action Space:](https://github.com/XinJingHao/SAC-Discrete-Pytorch)
+ [Soft Actor Critic(SAC) for Continuous Action Space:](https://github.com/XinJingHao/SAC-Continuous-Pytorch)
+ [Actor-Sharer-Learner(ASL):](https://github.com/XinJingHao/Actor-Sharer-Learner)

<br/>

## Recommended Resources for DRL
### Books：
+ [《Reinforcement learning: An introduction》](https://books.google.com.sg/books?hl=zh-CN&lr=&id=uWV0DwAAQBAJ&oi=fnd&pg=PR7&dq=Reinforcement+Learning&ots=mivIu01Xp6&sig=zQ6jkZRxJop4fkAgScMgzULGlbY&redir_esc=y#v=onepage&q&f=false)--Richard S. Sutton
+ 《深度学习入门：基于Python的理论与实现》--斋藤康毅

### Online Courses:
+ [RL Courses(bilibili)](https://www.bilibili.com/video/BV1UE411G78S?p=1&vd_source=df4b7370976f5ca5034cc18488eec368)--李宏毅(Hongyi Li)
+ [RL Courses(Youtube)](https://www.youtube.com/watch?v=z95ZYgPgXOY&list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_)--李宏毅(Hongyi Li)
+ [UCL Course on RL](https://www.davidsilver.uk/teaching/)--David Silver
+ [动手强化学习](https://hrl.boyuai.com/chapter/1/%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)--上海交通大学

### Blogs:
+ [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/)
+ [Policy Gradient Theorem --Cangxi](https://zhuanlan.zhihu.com/p/491647161)
+ [Policy Gradient Algorithms --Lilian](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/)
+ [Theorem of PPO](https://zhuanlan.zhihu.com/p/563166533)
+ [The 37 Implementation Details of Proximal Policy Optimization](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
+ [Prioritized Experience Replay](https://zhuanlan.zhihu.com/p/631171588)
+ [Soft Actor Critic](https://zhuanlan.zhihu.com/p/566722896)
+ [A (Long) Peek into Reinforcement Learning --Lilian](https://lilianweng.github.io/posts/2018-02-19-rl-overview/)
+ [Introduction to TD3](https://zhuanlan.zhihu.com/p/409536699)

### Simulation Environments:
+ [gym](https://www.gymlibrary.dev/)
+ [gymnasium](https://gymnasium.farama.org/)
+ [Sparrow](https://github.com/XinJingHao/Sparrow-V0)
+ [Envpool](https://envpool.readthedocs.io/en/latest/index.html)
+ [ROS](https://www.ros.org/)
+ [Webots](https://cyberbotics.com/)

<br/>

# Important Papers
DQN: [Mnih V, Kavukcuoglu K, Silver D, et al. Human-level control through deep reinforcement learning[J]. nature, 2015, 518(7540): 529-533.](https://www.nature.com/articles/nature14236/?source=post_page---------------------------)

Double DQN: [Van Hasselt H, Guez A, Silver D. Deep reinforcement learning with double q-learning[C]//Proceedings of the AAAI conference on artificial intelligence. 2016, 30(1).](https://ojs.aaai.org/index.php/AAAI/article/view/10295)

PER: [Schaul T, Quan J, Antonoglou I, et al. Prioritized experience replay[J]. arXiv preprint arXiv:1511.05952, 2015.](https://arxiv.org/abs/1511.05952)

PPO: [Schulman J, Wolski F, Dhariwal P, et al. Proximal policy optimization algorithms[J]. arXiv preprint arXiv:1707.06347, 2017.](https://arxiv.org/pdf/1707.06347.pdf)

DDPG: [Lillicrap T P, Hunt J J, Pritzel A, et al. Continuous control with deep reinforcement learning[J]. arXiv preprint arXiv:1509.02971, 2015.](https://arxiv.org/abs/1509.02971)

TD3: [Fujimoto S, Hoof H, Meger D. Addressing function approximation error in actor-critic methods[C]//International conference on machine learning. PMLR, 2018: 1587-1596.](https://proceedings.mlr.press/v80/fujimoto18a.html)

SAC: [Haarnoja T, Zhou A, Abbeel P, et al. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor[C]//International conference on machine learning. PMLR, 2018: 1861-1870.](https://proceedings.mlr.press/v80/haarnoja18b)

ASL: [Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity](https://arxiv.org/abs/2305.04180)

<br/>


## Training Curves of my Code:

### [Q-learning:](https://github.com/XinJingHao/Q-learning)
<img src="https://github.com/XinJingHao/Q-learning/blob/main/result.svg" width=320>

### [DQN/DDQN on Classic Control:](https://github.com/XinJingHao/DQN-DDQN-Pytorch)
<img src="https://github.com/XinJingHao/DQN-DDQN-Pytorch/blob/main/IMGs/DQN_DDQN_result.png" width=700>


### [DQN/DDQN on Atari Game:](https://github.com/XinJingHao/DQN-DDQN-Atari-Pytorch)
Pong| Enduro
:-----------------------:|:-----------------------:|
<img src="https://github.com/XinJingHao/DQN-DDQN-Atari-Pytorch/raw/main/IMGs/Pong.png" width="320" height="200">| <img src="https://github.com/XinJingHao/DQN-DDQN-Atari-Pytorch/raw/main/IMGs/Enduro.png" width="320" height="200">

<br/>


### [Prioritized DQN/DDQN on Classic Control:](https://github.com/XinJingHao/Prioritized-DQN-DDQN-Pytorch)
|                           CartPole                           |                         LunarLander                          |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="https://github.com/XinJingHao/Prioritized-DQN-DDQN-Pytorch/blob/main/LightPriorDQN_gym0.2x/IMGs/CPV1.svg" width="320" height="200"> | <img src="https://github.com/XinJingHao/Prioritized-DQN-DDQN-Pytorch/blob/main/LightPriorDQN_gym0.2x/IMGs/LLDV2.svg" width="320" height="200"> |

<br/>

### [PPO Discrete:](https://github.com/XinJingHao/PPO-Discrete-Pytorch)
<img src="https://github.com/XinJingHao/PPO-Discrete-Pytorch/blob/main/result.jpg" width=700>

### [PPO Continuous:](https://github.com/XinJingHao/PPO-Continuous-Pytorch)
<img src="https://github.com/XinJingHao/PPO-Continuous-Pytorch/blob/main/ppo_result.jpg">

### [DDPG:](https://github.com/XinJingHao/DDPG-Pytorch)
Pendulum| LunarLanderContinuous
:-----------------------:|:-----------------------:|
<img src="https://github.com/XinJingHao/DDPG-Pytorch/blob/main/IMGs/ddpg_pv0.svg" width="320" height="200">| <img src="https://github.com/XinJingHao/DDPG-Pytorch/blob/main/IMGs/ddpg_lld.svg" width="320" height="200"> 

<br/>

### [TD3:](https://github.com/XinJingHao/TD3-Pytorch)
<img src="https://github.com/XinJingHao/TD3-Pytorch/blob/main/images/TD3results.png" width=700>

### [SAC Continuous:](https://github.com/XinJingHao/SAC-Continuous-Pytorch)
<img src="https://github.com/XinJingHao/SAC-Continuous-Pytorch/blob/main/imgs/result.jpg" width=700>

### [SAC Discrete:](https://github.com/XinJingHao/SAC-Discrete-Pytorch)
<img src="https://github.com/XinJingHao/SAC-Discrete-Pytorch/blob/main/imgs/sacd_result.jpg" width=700>

### [Actor-Sharer-Learner (ASL):](https://github.com/XinJingHao/Actor-Sharer-Learner)
<div align="left">
<img width="70%" height="auto" src="https://github.com/XinJingHao/Images/blob/main/asl/ss_e.svg">
</div>


